{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Art_Generation_with_Neural_Style_Transfer_v3a",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skfo763/Google-ML-Bootcamp-phase1/blob/main/course4/week4/Art_Generation_with_Neural_Style_Transfer_v3a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkiZSjWn0j_W"
      },
      "source": [
        "# Deep Learning & Art: Neural Style Transfer\n",
        "\n",
        "이번 과제에서, 여러분은[ Gatys et al. (2015).](https://arxiv.org/abs/1508.06576) 이 개발한 알고리즘인 Neural Style Transfer에 대해서 배워볼 것입니다.\n",
        "\n",
        "** 이번 과제에서 여러분은 : **\n",
        "- Neural style transfer 알고리즘을 직접 구현합니다.\n",
        "- 위 알고리즘을 사용해서 참신한 예술 작품을 생성합니다.\n",
        "\n",
        "이전까지 공부했던 대부분의 인공신경망 알고리즘은 파라미터 세트를 얻기 위해 비용 함수를 최적화합니다. 그에 반해, 이번에 새로 배울 Neural style transfer에서는 픽셀 값을 얻기 위해 비용 함수를 최적화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1humF18m1UyI"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "from nst_utils import *\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pprint\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdqUb5xu1Xxe"
      },
      "source": [
        "## 1 - Problem Statement\n",
        "\n",
        "Neural Style Transfer(NST)는 딥러닝에서 가장 흥미로운 몇 가지 기법 중 하나입니다. 아래 그림에서 볼 수 있듯이, NST 알고리즘은 두 이미지를 하나로 합칩니다. 좀더 정확히는 **\"contents\" 이미지 (C) 와 \"style\" 이미지 (S) 를 합쳐 \"geneated\" 이미지 (G) 를 만드는 알고리즘입니다.**\n",
        "\n",
        "즉 생성된 이미지 G는 \"content\" 이미지 C와 \"style\" 이미지 S가 결합된 형태입니다.\n",
        "\n",
        "이 예에서는 대표적인 인상파 화가인 클로드 모네의 그림 (style 이미지 S)과 파리 루브르 박물관의 이미지 (content 이미지 C)를 결합한 이미지를 생성합니다.\n",
        "\n",
        "<img src=\"arts/louvre_generated.png\" style=\"width:750px;height:200px;\">\n",
        "\n",
        "어떻게 이런 작품을 만들 수 있는지 알아봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc1mt3xA2cZO"
      },
      "source": [
        "## 2 - Transfer Learning\n",
        "\n",
        "NST (Neural Style Transfer)는 이전에 훈련 된 컨볼 루션 신경망을 사용하며 그 위에서 이루어집니다. 사전에 훈련 된 네트워크를 새로운 작업에 적용하는 아이디어를 `transfer learning` 이라고 합니다.\n",
        "\n",
        "이번 과제에서는 [원본 NST 논문](https://arxiv.org/abs/1508.06576)에 맞게 VGG 네트워크를 사용합니다. 특히 이번에는 19개의 은닉층을 가진 VGG-19 버전을 사용할 것입니다. 이 모델은 이미 매우 큰 ImageNet 데이터베이스에서 학습되었으므로, 다양한 하위 레벨 feature(얕은 레이어)와 상위 레벨 feature(깊은 레이어)를 인식하는 방법을 배웠습니다.\n",
        "\n",
        "아래 코드를 실행하여 VGG 모델에서 학습된 파라미터를 다운로드합니다. 몇 초 정도 걸릴 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqtx1d_62VLu"
      },
      "source": [
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\n",
        "pp.pprint(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qeahfs73ZYZ"
      },
      "source": [
        "- 위 모델은 python 딕셔너리에 저장되어 있습니다.\n",
        "- 딕셔너리 자료구조는 각 레이어에 대해 key-value 쌍의 데이터를 가지고 있습니다.\n",
        "- 'key' 값이 변수명이고, 'value'는 해당 레이어의 텐서 값을 의미합니다.\n",
        "\n",
        "#### Assign input image to the model's input layer\n",
        "이 네트워크를 사용해서 이미지를 분석하려면 이미지를 모델에 투입하기만 하면 됩니다. TensorFlow 에서는 [tf.assign](https://www.tensorflow.org/api_docs/python/tf/assign) 함수를 사용하여 이를 수행 할 수 있습니다. 특히 다음과 같이 할당 기능을 사용합니다.\n",
        "```python\n",
        "model[\"input\"].assign(image)\n",
        "```\n",
        "이 코드는 이미지를 모델에 대한 입력으로 할당합니다.\n",
        "\n",
        "#### Activate a layer\n",
        "그런 다음 특정 레이어(예 : 이 이미지에서 네트워크가 실행될 때 레이어 `4_2`) 의 활성화 변수에 액세스하려면 다음과 같이 텐서 `conv4_2`에서 TensorFlow 세션을 실행합니다.\n",
        "```python\n",
        "sess.run(model[\"conv4_2\"])\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUImwVTt8fz4"
      },
      "source": [
        "## 3 - Neural Style Transfer(NST)\n",
        "\n",
        "지금부터 다음 3단계를 거쳐서 Neural Style Transfer(NST) 알고리즘을 구현해보도록 하겠습니다.\n",
        "\n",
        "- content 비용함수 $J_{content}(C,G)$ 구현하기\n",
        "- style 비용함수 $J_{style}(S,G)$ 구현하기\n",
        "- 두 비용함수를 한데 모아 $J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$ 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnok4W5P82TC"
      },
      "source": [
        "### 3.1 - Computing the content cost\n",
        "\n",
        "이번 과제에서, 컨텐츠(content) 이미지 C는 파리 루브르 박물관 사진입니다. 아래 코드를 실행시켜서 루브르 박물관 이미지가 어떻게 생겼는지 확인해보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxYYnNns64k1"
      },
      "source": [
        "content_image = scipy.misc.imread(\"images/louvre.jpg\")\n",
        "imshow(content_image);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXGzTTfQ9E-s"
      },
      "source": [
        "컨텐츠 이미지 (C)는 구름이 적당히 드리운 하늘 아래 파리의 건축물들 사이에 둘러쌓인 루브르 박물관의 유리 피라미드를 담고 있습니다. \n",
        "\n",
        "#### 3.1.1 - Make generated image G match the content of image C\n",
        "\n",
        "**Shallower versus deeper layers**\n",
        "\n",
        "- 컨볼루션 신경망의 얕은 레이어 부분은 모서리나 단순한 텍스쳐 등 저수준의 feature를 감지합니다\n",
        "- 깊은 레이어는 더 복잡한 텍스처 및 물체의 클래스와 같은 더 높은 수준의 feature를 감지하는 경향이 있습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Choose a \"middle\" activation layer $a^{[l]}$**\n",
        "\n",
        "우리는 \"generated\" 이미지 G가 입력 content 이미지 C와 유사한 내용을 갖기를 원합니다. 이미지의 content를 나타내기 위해 특정 레이어의 활성화를 선택했다고 가정합니다.\n",
        "\n",
        "- 실제로 너무 얕거나 너무 깊지 않은 네트워크 중간에 있는 레이어를 선택하면 시각적으로 가장 만족스러운 결과를 얻을 수 있습니다.\n",
        "- (이 과제를 다 마친 후 다시 돌아와서 다른 레이어를 사용하여 실험하여 결과가 어떻게 다른지 확인해보세요.)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Forward propagate image \"C\"**\n",
        "\n",
        "- 이미지 C를 사전 훈련된 VGG 네트워크의 입력으로 집어넣고, forward propagation을 수행합니다.\n",
        "- $a^{(c)}$를 위에서 선택한 특정 은닉층의 활성화 변수라고 해봅시다.(동영상 강의에선 해당 변수를 $a^{[l](C)}$로 적었습니다, 하지만 과제에서는 편의를 위해 위첨자 $[l]$을 생략하겠습니다.) 이 변수는 $n_H \\times n_W \\times n_C$의 텐서입니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Forward propagate image \"G\"**\n",
        "\n",
        "- 위의 과정을 이미지 G에 대해서도 반복적으로 수행하세요. G를 입력으로 하여 forward propagation을 수행합니다.\n",
        "- $a^{(G)}$를 위에 상응하는 은닉층의 활성화 변수로 설정합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Content Cost Function $J_{content}(C, G)$**\n",
        "\n",
        "content 비용 함수를 다음과 같이 정의할 수 있습니다.\n",
        "\n",
        "$$J_{content}(C,G) =  \\frac{1}{4 \\times n_H \\times n_W \\times n_C}\\sum _{ \\text{all entries}} (a^{(C)} - a^{(G)})^2\\tag{1} $$\n",
        "\n",
        "- 여기서, $n_H, n_W, n_C$는 위에서 여러분이 선택한 은닉층의 각 높이, 너비, 채널의 수이며, 정규화된 방식으로 표현됩니다.\n",
        "- 보다 명확히 하기 위해, $a^{(C)}$ 및 $a^{(G)}$ 는 히든 레이어의 활성화에 해당하는 3D 볼륨입니다.\n",
        "- 비용 $J_{content}(C, G)$ 를 계산하려면 아래 그림과 같이 3D 볼륨을 2D 매트릭스로 펼치는 것이 편리 할 수도 있습니다.\n",
        "- 기술적으로는 $J_{content}$ 를 계산하는 데 이 '펼치는' 단계가 필요하지 않지만 나중에 style 비용 $J_ {style}$를 계산하기 위해 유사한 작업을 수행해야 할 때 좋은 방법이 될 것입니다.\n",
        "\n",
        "<img src=\"arts/NST_LOSS.png\" style=\"width:800px;height:400px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xlS9BPyIWnu"
      },
      "source": [
        "**연습 문제** : Tensorflow를 사용해서 \"content cost\" 를 계산하세요.\n",
        "\n",
        "**지시 사항** : 위 함수를 구현하기 위해서는 아래 3단계를 따르세요.\n",
        "\n",
        "1. `a_G`로부터 배열의 차원을 구합니다 : \n",
        "  - tensor `X` 로부터 차원을 구해내려면, `X.get_shape().as_list()` 코드를 사용합니다.\n",
        "2. `a_C`와 `a_G`를 위 그림에 나온대로 펼쳐보세요.\n",
        "  - `tf.transpose` 함수와 `tf.reshape` 함수를 사용하세요.\n",
        "3. content cost를 계산하세요.\n",
        "  - `tf.reduce_sum`, `tf.square`, `tf.subtract` 함수를 사용하세요.\n",
        "\n",
        "**\"Unrolling(펼치기)\" 연산을 위한 추가적인 힌트**\n",
        "\n",
        "\n",
        "- 텐서를 펼치기 위해 모양을 $(m, n_H, n_W, n_C) $에서 $ (m, n_H \\times n_W, n_C)$로 변경하려고합니다.\n",
        "- `tf.reshape (tensor, shape)` 는 원하는 출력 shape를 나타내는 정수 목록을 인자로 받습니다.\n",
        "- `shape` 매개 변수의 경우 `-1` 은 출력 텐서가 원래 텐서의 모든 값을 포함하도록 올바른 차원 크기를 선택하도록 합니다.\n",
        "- 따라서 `tf.reshape(a_C, shape = [m, n_H * n_W, n_C])` 는 `tf.reshape (a_C, shape = [m, -1, n_C])` 와 동일한 결과를 리턴합니다.\n",
        "- 차원을 다시 정렬하려면 `tf.transpose (tensor, perm)` 를 사용할 수 있습니다. 여기서 `perm` 은 차원의 원래 색인을 포함하는 정수 목록입니다.\n",
        "- 예를 들어 `tf.transpose (a_C, perm = [0,3,1,2])`는 차원을 $(m, n_H, n_W, n_C)$ 에서 $(m, n_C, n_H, n_W)$ 로 변경합니다.\n",
        "- 텐서를 펼치는 방법은 이외에도 여러 가지가 있습니다.\n",
        "- 이 경우 텐서를 'unroll'하기 위해 `tf.transpose` 를 사용할 필요는 없지만 마주하게 될 다른 상황에 대비해 연습하고 이해하는 데 유용한 함수입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o42yuFALIP48"
      },
      "source": [
        "# GRADED FUNCTION: compute_content_cost\n",
        "\n",
        "def compute_content_cost(a_C, a_G):\n",
        "    \"\"\"\n",
        "    Computes the content cost\n",
        "    \n",
        "    Arguments:\n",
        "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
        "    \n",
        "    Returns: \n",
        "    J_content -- scalar that you compute using equation 1 above.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from a_G (≈1 line)\n",
        "    m, n_H, n_W, n_C = None\n",
        "    \n",
        "    # Reshape a_C and a_G (≈2 lines)\n",
        "    a_C_unrolled = None\n",
        "    a_G_unrolled = None\n",
        "    \n",
        "    # compute the cost with tensorflow (≈1 line)\n",
        "    J_content = None\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J_content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX6kRpSDJDqu"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    tf.set_random_seed(1)\n",
        "    a_C = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
        "    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
        "    J_content = compute_content_cost(a_C, a_G)\n",
        "    print(\"J_content = \" + str(J_content.eval()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9E_eJxYJDfP"
      },
      "source": [
        "**모범 답안**:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <b>J_content</b>\n",
        "        </td>\n",
        "        <td>\n",
        "           6.76559\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZGcVvdTJqQX"
      },
      "source": [
        "#### 기억해야 할 사항\n",
        "- content cost는 신경망의 은닉층 활성화를 취하고 $a ^ {(C)}$와 $ a^{(G)}$가 얼마나 다른지 측정합니다.\n",
        "- 나중에 content cost를 최소화하면 $G$에 $C$와 유사한 컨텐츠가 있는지 확인하는 데 도움이됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DEe-7DNKtqC"
      },
      "source": [
        "### 3.2 - Computing the style cost\n",
        "\n",
        "이번 예제에서는 다음 스타일 이미지를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byDCVNp1JIzm"
      },
      "source": [
        "style_image = scipy.misc.imread(\"images/monet_800600.jpg\")\n",
        "imshow(style_image);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpIfMGRHK8AO"
      },
      "source": [
        "위 그림은 [인상파](https://en.wikipedia.org/wiki/Impressionism) 스타일로 그려졌습니다.\n",
        "\n",
        "이제 \"style\" 비용 함수 $ J_{style}(S, G)$ 를 정의하는 방법을 살펴 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmiv9CSMy866"
      },
      "source": [
        "#### 3.2.1 - Style matrix\n",
        "\n",
        "**Gram matix**\n",
        "\n",
        "- style matrix는 \"Gram matrix\" 라는 이름으로도 불립니다.\n",
        "- 선형 대수학에서, $(v_{1},\\dots ,v_{n})$인 Gram matrix G는 엔트리가 ${\\displaystyle G_{ij} = v_{i}^T v_{j} = np.dot(v_{i}, v_{j})}$인 내적 행렬입니다. \n",
        "- 즉 $G_{ij}$는 $v_i$가 $v_j$와 얼마나 유사한지 비교합니다. 만약 두 값이 매우 유사하다면, 더 큰 내적을 가진다고 예상할 수 있고, 따라서 $G_{ij}$가 더 커질 것입니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Two meanings of the variable G**\n",
        "\n",
        "- 아래를 읽어보면 현재 사용하고 있는 변수 이름에 불필요한 충돌이 있음을 알 수 있습니다. 이번 과제는 참고 문헌에서 사용되는 일반적인 용어를 따르고 있습니다.\n",
        "- $G$는 Style matrix(Gram matrix)를 의미합니다.\n",
        "- $G$는 생성된 이미지를 나타내기도 합니다.\n",
        "- 이번 과제에서는 $G_{gram}$을 사용하여 Gram matrix를 나타내고, $G$를 사용하여 생성된 이미지를 나타내도록 하겠습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Compute G_{gram}**\n",
        "\n",
        "Neural Style Transfer(NST)에서, 펼쳐진 버전의 행렬을 자기 자신의 전치 행렬과 곱하는 연산을 수행함으로서 Style matrix를 구할 수 있습니다\n",
        "\n",
        "<img src=\"arts/NST_GM.png\" style=\"width:900px;height:300px;\">\n",
        "\n",
        "$$\\mathbf{G}_{gram} = \\mathbf{A}_{unrolled} \\mathbf{A}_{unrolled}^T$$\n",
        "\n",
        "$G_{(gram),i,j}$ : **correlation(상관 계수)**\n",
        "\n",
        "위 연산의 결과값은 $(n_C, n_C)$ 의 shape를 가진 행렬로, $n_C$는 채널(필터)의 개수를 의미합니다. $G_{(gram), i, j}$는 필터 i의 활성화 값이 필터 j의 활성화 값과 얼마나 비슷한지를 측정합니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "$G_{(gram), i, i}$ : **prevalence of patterns or textures**\n",
        "\n",
        "- 행렬의 대각선에 해당하는 element인 $G _{(gram)ii}$ 는 필터 $i$의 활성화 정도를 측정합니다.\n",
        "- 예를 들어 $i$ 필터가 특정 이미지에서 수직인 텍스처를 감지한다고 가정합니다. 그런 다음 $G_{(gram) ii}$는 이미지 전체에 수직 텍스처가 얼마나 일반적으로 나타나는지 측정합니다.\n",
        "- $G_{(gram)ii}$가 크면 이미지에 수직인 텍스처가 많음을 의미합니다.\n",
        "\n",
        "스타일 매트릭스 $G_{gram}$는 서로 다른 유형의 featuree들의 보급률(널리 퍼진 정도)과, 서로 다른 feature가 얼마나 같이 발생하는지의 양을 포착하여 이미지의 스타일을 측정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgzz59j-7jwF"
      },
      "source": [
        "**연습 문제**:\n",
        "- 텐서플로우를 사용해, 특정 행렬 A의 Gram matrix를 계산하는 함수를 구현해보세요.\n",
        "- Gram matrix를 구하는 공식은 다음과 같습니다 : $G_A = AA^{T}$\n",
        "- `matmul` 함수와 `transpose` 함수를 사용해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDFGTr9X7h6v"
      },
      "source": [
        "# GRADED FUNCTION: gram_matrix\n",
        "\n",
        "def gram_matrix(A):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    A -- matrix of shape (n_C, n_H*n_W)\n",
        "    \n",
        "    Returns:\n",
        "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    GA = None\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return GA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aRoXu_b70xw"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    tf.set_random_seed(1)\n",
        "    A = tf.random_normal([3, 2*1], mean=1, stddev=4)\n",
        "    GA = gram_matrix(A)\n",
        "    \n",
        "    print(\"GA = \\n\" + str(GA.eval()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud5jXo5G70lQ"
      },
      "source": [
        "**모범 답안**:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <b>GA</b>\n",
        "        </td>\n",
        "        <td>\n",
        "           [[  6.42230511  -4.42912197  -2.09668207] <br>\n",
        " [ -4.42912197  19.46583748  19.56387138] <br>\n",
        " [ -2.09668207  19.56387138  20.6864624 ]]\n",
        "        </td>\n",
        "    </tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1RTSS6B8RLt"
      },
      "source": [
        "#### 3.2.2 - Style cost\n",
        "\n",
        "여러분의 목표는, \"Style\" 이미지 S에 대한 Gram matrix와 \"generated\" 이미지 G의 Gram matrix 사이의 거리를 최소화하는 것입니다.\n",
        "\n",
        "- 지금까지 우리는 단 하나의 은닉층 $a^{[l]}$ 만을 사용했습니다.\n",
        "- 해당 레이어에 상응하는 style 비용함수는 다음과 같이 정의됩니다.\n",
        "\n",
        "$$J_{style}^{[l]}(S,G) = \\frac{1}{4 \\times {n_C}^2 \\times (n_H \\times n_W)^2} \\sum _{i=1}^{n_C}\\sum_{j=1}^{n_C}(G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2\\tag{2} $$\n",
        "\n",
        "- $G_{gram}^{(S)}$는 style 이미지에 대한 Gram matrix를 의미합니다.\n",
        "- $G_{gram}^{(G)}$는 generated 이미지에 대한 Gram matrix를 의미합니다.\n",
        "- 이 비용은 신경망의 특정 히든 레이어인 $a^{[l]}$에 대한 활성화 값을 사용하여 계산된다는 것을 기억하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG2oyfEB9oMY"
      },
      "source": [
        "**연습 문제** : 단일 신경망에 대한 style 비용 함수를 작성하세요.\n",
        "\n",
        "**지시 사항** : 함수 구현에 있어 다음 세 단계를 따르세요.\n",
        "\n",
        "1. 특정 은닉층의 활성화 값인 a_G에 대한 차원을 구하세요.\n",
        "  - 텐서 X로부터 차원을 구하기 위해선 `X.get_shape().as_list()` 코드를 사용합니다.\n",
        "2. 스타일 이미지와 생성된 이미지의 해당 은닉층에서의 활성화변수인 `a_S`와 `a_G`를 2D 행렬로 펼쳐보세요. 아래에 그림에 설명된대로 하면 됩니다(\"computing the content const\"와 \"style matrix\" 섹션을 참조하세요)\n",
        "  - [tf.transpose](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/transpose) 함수와 [tf.reshape](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/reshape) 함수를 사용하세요.\n",
        "3. 이미지 S와 G의 style 행렬을 계산합니다. (이전에 작성한 함수를 사용하세요.)\n",
        "4. style cost를 계산합니다.\n",
        "     - [tf.reduce_sum](https://www.tensorflow.org/api_docs/python/tf/reduce_sum), [tf.square](https://www.tensorflow.org/api_docs/python/tf/square) 및 [tf.subtract](https://www.tensorflow.org/api_docs/python/tf/subtract) 함수를 사용하세요.\n",
        "\n",
        "**Additional Hints**\n",
        "- 활성화 변수 행렬의 차원이 $(m, n_H, n_W, n_C)$ 인 반면 원하는 펼쳐진 행렬의 shape는 $(n_C, n_H * n_W)$이므로 필터 차원 $n_C$의 순서가 변경됩니다. 따라서`tf.transpose`를 사용하여 필터 차원의 순서를 변경할 수 있습니다.\n",
        "- $\\mathbf{G}_{gram} = \\mathbf{A}_{} \\mathbf{A}_{}^T$ 행렬곱을 수행하기 위해서, `tf.transpose`함수에 대해 `perm` 파라미터를 지정해야합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzMmubCZ9k9E"
      },
      "source": [
        "# GRADED FUNCTION: compute_layer_style_cost\n",
        "\n",
        "def compute_layer_style_cost(a_S, a_G):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
        "    \n",
        "    Returns: \n",
        "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Retrieve dimensions from a_G (≈1 line)\n",
        "    m, n_H, n_W, n_C = None\n",
        "    \n",
        "    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n",
        "    a_S = None\n",
        "    a_G = None\n",
        "\n",
        "    # Computing gram_matrices for both images S and G (≈2 lines)\n",
        "    GS = None\n",
        "    GG = None\n",
        "\n",
        "    # Computing the loss (≈1 line)\n",
        "    J_style_layer = None\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J_style_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P-Q-hHM_dE8"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    tf.set_random_seed(1)\n",
        "    a_S = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
        "    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
        "    J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
        "    \n",
        "    print(\"J_style_layer = \" + str(J_style_layer.eval()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIhpsL3n_eXD"
      },
      "source": [
        "**모범 답안**:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <b>J_style_layer</b>\n",
        "        </td>\n",
        "        <td>\n",
        "           9.19028\n",
        "        </td>\n",
        "    </tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iial1H76_ibi"
      },
      "source": [
        "#### 3.2.3 Style Weights\n",
        "\n",
        "- 지금까지 하나의 은닉층에서만 style을 구했습니다.\n",
        "- 여러 레이어의 style cost를 병합하면 더 나은 결과를 얻을 수 있습니다.\n",
        "- 각 레이어에는 해당 레이어가 style cost에 기여하는 정도를 의미하는 가중치 ($\\lambda^{[l]}$)가 부여됩니다.\n",
        "- 이 과제를 완료한 후 다시 돌아와서 generated 이미지 $G$가 어떻게 변경되는지 다른 가중치로 실험 해보세요.\n",
        "- 기본적으로 각 레이어에 동일한 가중치를 부여합니다. 가중치의 합은 1이됩니다. ($\\sum_{l}^L \\lambda^{[l]} = 1$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP989NkVAMHk"
      },
      "source": [
        "STYLE_LAYERS = [\n",
        "    ('conv1_1', 0.2),\n",
        "    ('conv2_1', 0.2),\n",
        "    ('conv3_1', 0.2),\n",
        "    ('conv4_1', 0.2),\n",
        "    ('conv5_1', 0.2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiHOqFzFAOs2"
      },
      "source": [
        "다음과 같이 여러 레이어의 style cost를 결합할 수 있습니다.\n",
        "\n",
        "$$ J_{style}(S, G) = \\sum_{l} \\lambda^{[l]} J^{[l]}_{style}(S, G) $$\n",
        "\n",
        "$ \\lambda^{[l]} $의 값은`STYLE_LAYERS`에 제공됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlMB7DJxAkgc"
      },
      "source": [
        "### 연습 문제 : style cost 계산\n",
        "\n",
        "- 우리는 `compute_style_cost(...)` 함수를 구현했습니다.\n",
        "- `compute_layer_style_cost(...)`를 여러 번 호출하고 `STYLE_LAYERS`의 값을 사용하여 결과에 가중치를 부여합니다.\n",
        "- 위 과정이 뭘 의미하는지 이해하기 위해서는 아래 글을 쭉 읽어보세요.\n",
        "\n",
        "<br>\n",
        "\n",
        "**`compute_style_cost` 설명**\n",
        "각 레이어에 대해 :\n",
        "- 현재 레이어의 활성화 (출력 텐서)를 선택합니다.\n",
        "- 현재 레이어에서 style 이미지 \"S\"의 스타일을 가져옵니다.\n",
        "- 현재 레이어에서 generated 이미지 \"G\"의 스타일을 가져옵니다.\n",
        "- 현재 레이어에 대한 style cost를 계산합니다\n",
        "- 전체 style cost (J_style)에 가중치가 적용된 단일 레이어에서의 style cost를 더합니다.\n",
        "\n",
        "루프를 완료하면 :\n",
        "- 전체 style cost를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anw5hjYbAbCW"
      },
      "source": [
        "def compute_style_cost(model, STYLE_LAYERS):\n",
        "    \"\"\"\n",
        "    Computes the overall style cost from several chosen layers\n",
        "    \n",
        "    Arguments:\n",
        "    model -- our tensorflow model\n",
        "    STYLE_LAYERS -- A python list containing:\n",
        "                        - the names of the layers we would like to extract style from\n",
        "                        - a coefficient for each of them\n",
        "    \n",
        "    Returns: \n",
        "    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n",
        "    \"\"\"\n",
        "    \n",
        "    # initialize the overall style cost\n",
        "    J_style = 0\n",
        "\n",
        "    for layer_name, coeff in STYLE_LAYERS:\n",
        "\n",
        "        # Select the output tensor of the currently selected layer\n",
        "        out = model[layer_name]\n",
        "\n",
        "        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out\n",
        "        a_S = sess.run(out)\n",
        "\n",
        "        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] \n",
        "        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
        "        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
        "        a_G = out\n",
        "        \n",
        "        # Compute style_cost for the current layer\n",
        "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
        "\n",
        "        # Add coeff * J_style_layer of this layer to overall style cost\n",
        "        J_style += coeff * J_style_layer\n",
        "\n",
        "    return J_style"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMNPIC9GBVmy"
      },
      "source": [
        "** 참고 ** : 위의 for 루프의 내부 루프에서 'a_G'는 텐서이며 아직 평가되지 않았습니다. 아래 `model_nn()` 에서 TensorFlow 그래프를 실행할 때 매 반복마다 평가되고 업데이트됩니다.\n",
        "\n",
        "\n",
        "## 기억해야 할 사항\n",
        "- 히든 레이어 활성화의 그램 행렬을 이용하여 이미지의 스타일을 표현할 수 있습니다.\n",
        "- 이 표현을 여러 다른 레이어에서 결합하여 더 나은 결과를 얻습니다.\n",
        "- 이것은 일반적으로 단일 히든 레이어를 사용하는 것으로 충분할 경우 콘텐츠 표현과는 대조적입니다.\n",
        "- 스타일 비용을 최소화하면 $ G $ 이미지가 $ S $ 이미지의 스타일을 따르게됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyxMaZPcHe8J"
      },
      "source": [
        "### 3.3 - Defining the total cost to optimize\n",
        "\n",
        "마지막으로 style, contents 비용을 모두 최소화하는 비용 함수를 만들어 보겠습니다. 공식은 다음과 같습니다.\n",
        "\n",
        "$$ J (G) = \\ alpha J_ {content} (C, G) + \\ beta J_ {style} (S, G) $$\n",
        "\n",
        "**연습 문제** : content cost와 style cost를 모두 포함하는 총 비용 함수를 구현하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mexutE3BboG"
      },
      "source": [
        "# GRADED FUNCTION: total_cost\n",
        "\n",
        "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
        "    \"\"\"\n",
        "    Computes the total cost function\n",
        "    \n",
        "    Arguments:\n",
        "    J_content -- content cost coded above\n",
        "    J_style -- style cost coded above\n",
        "    alpha -- hyperparameter weighting the importance of the content cost\n",
        "    beta -- hyperparameter weighting the importance of the style cost\n",
        "    \n",
        "    Returns:\n",
        "    J -- total cost as defined by the formula above.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ### (≈1 line)\n",
        "    J = (alpha * J_content) + (beta * J_style)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdfmw2NvHyxQ"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as test:\n",
        "    np.random.seed(3)\n",
        "    J_content = np.random.randn()    \n",
        "    J_style = np.random.randn()\n",
        "    J = total_cost(J_content, J_style)\n",
        "    print(\"J = \" + str(J))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2OAjVlAHzRx"
      },
      "source": [
        "**모범 답안**:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <b>J</b>\n",
        "        </td>\n",
        "        <td>\n",
        "           35.34667875478276\n",
        "        </td>\n",
        "    </tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKktbKbRH5q9"
      },
      "source": [
        "## 기억해야 할 사항\n",
        "- total cost는 content cost $J_{content}(C, G)$와 style cost $J_{style}(S, G)$ 의 일차 결합(선형 결합)입니다.\n",
        "-$\\alpha$ 및 $\\beta$는 content와 style 간의 상대적 가중치를 제어하는 하이퍼 파라미터입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZcclQBVIRFq"
      },
      "source": [
        "## 4 - Solving the optimization problem\n",
        "\n",
        "\n",
        "마지막으로 지금까지 구현한 모든 함수를 한데 모아 Neural Style Transfer을 완성해봅시다.\n",
        "\n",
        "프로그램이 수행해야하는 작업은 다음과 같습니다.\n",
        "\n",
        "1. Interactive Session 생성\n",
        "2. 콘텐츠 이미지 불러오기\n",
        "3. 스타일 이미지 불러오기\n",
        "4. 생성 할 이미지를 임의로 초기화\n",
        "5. VGG19 모델로드\n",
        "6. TensorFlow 그래프를 만듭니다.\n",
        "     - VGG19 모델을 통해 콘텐츠 이미지를 실행하고 콘텐츠 비용을 계산\n",
        "     - VGG19 모델을 통해 스타일 이미지를 실행하고 스타일 비용을 계산\n",
        "     - 총 비용 계산\n",
        "     - 최적화 및 학습률 정의\n",
        "7. TensorFlow 그래프를 초기화하고 여러 번 반복하여 실행하여 모든 단계에서 생성 된 이미지를 업데이트합니다.\n",
        "\n",
        "개별 단계를 자세히 살펴 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwT7e_3GIq9S"
      },
      "source": [
        "#### Interactive Sessions\n",
        "\n",
        "이전에 총 비용 함수 $J(G)$를 구현했습니다. 이제 $G$와 관련하여 이를 최적화하기 위해 TensorFlow를 사용합니다.\n",
        "\n",
        "- 이를 위해 프로그램에서 그래프를 재설정하고 \"[Interactive Session](https://www.tensorflow.org/api_docs/python/tf/InteractiveSession)\"을 사용해야합니다.\n",
        "- 일반 세션과 달리 \"Interactive Session\"은 그래프를 작성하기위한 기본 세션으로 자체 설치됩니다.\n",
        "- 이렇게하면 세션 객체 (`sess.run()` 호출)를 계속 참조 할 필요없이 변수를 실행할 수 있으므로 코드가 단순화됩니다.\n",
        "\n",
        "#### Start the interactive session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0EWYQAWJAft"
      },
      "source": [
        "# Reset the graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Start interactive session\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfSMX7_XJCmw"
      },
      "source": [
        "#### Content image\n",
        "\n",
        "\"content\" 이미지인 루브르 박물관 사진을 불러와서 reshape, 정규화 해보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V82yKs0tH2mr"
      },
      "source": [
        "content_image = scipy.misc.imread(\"images/louvre_small.jpg\")\n",
        "content_image = reshape_and_normalize_image(content_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzPIA2EUK5j-"
      },
      "source": [
        "#### Style image\n",
        "\n",
        "다음으로는 \"style\" 이미지인 클로드 모네의 작품 불러와서 위와 마찬가지로 reshape하고 정규화 해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVWu3DYELBWX"
      },
      "source": [
        "style_image = scipy.misc.imread(\"images/monet.jpg\")\n",
        "style_image = reshape_and_normalize_image(style_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtXofIZHLEky"
      },
      "source": [
        "#### Generated image correlated with content image\n",
        "\n",
        "이제 \"generated\" 이미지를 content_image에서 생성 된 노이즈 이미지로 초기화합니다.\n",
        "\n",
        "- 생성 된 이미지는 콘텐츠 이미지와 약간의 상관 관계가 있습니다.\n",
        "- 생성 된 이미지의 픽셀은 대부분 노이즈이지만 콘텐츠 이미지와 약간의 상관 관계가 있도록 초기화하면 \"생성 된\"이미지의 콘텐츠가 \"콘텐츠\"이미지의 콘텐츠와 더 빠르게 일치하는 데 도움이됩니다.\n",
        "- `generate_noise_image(...)` 의 세부 사항을 보려면 `nst_utils.py` 에서 자유롭게 살펴보십시오. Jupyter 노트북의 왼쪽 상단 모서리에있는 \"파일-> 열기 ...\"를 클릭하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpLe00L0LX5s"
      },
      "source": [
        "generated_image = generate_noise_image(content_image)\n",
        "imshow(generated_image[0]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB1LZJ9LLZMf"
      },
      "source": [
        "#### Load pre-trained VGG19 model\n",
        "\n",
        "part (2)에서 설명했던대로, VGG 19 모델을 불러오겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QEUDpQeLgpZ"
      },
      "source": [
        "model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAwXOv57LhiB"
      },
      "source": [
        "#### Contents cost\n",
        "\n",
        "프로그램이 content cost를 계산하도록하기 위해 `a_C`및 `a_G`를 적절한 히든 레이어의 활성화 변수로 할당합니다. 콘텐츠 비용을 계산하기 위해 'conv4_2'레이어를 사용합니다. 아래 코드는 다음을 수행합니다.\n",
        "\n",
        "1. VGG 모델에 입력 할 콘텐츠 이미지를 할당합니다.\n",
        "2. a_C를 텐서로 설정하여 \"conv4_2\"레이어에 대한 은닉 레이어 활성화를 제공합니다.\n",
        "3. a_G를 동일한 레이어에 대해 은닉 레이어 활성화를 제공하는 텐서로 설정합니다.\n",
        "4. a_C 및 a_G를 사용하여 콘텐츠 비용을 계산합니다.\n",
        "\n",
        "**참고** : 이 시점에서 a_G는 텐서이며 평가되지 않았습니다. 아래의 `model_nn()` 에서 Tensorflow 그래프를 실행할 때 매 반복마다 평가되고 업데이트됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j0YrbsFLwHE"
      },
      "source": [
        "# Assign the content image to be the input of the VGG model.  \n",
        "sess.run(model['input'].assign(content_image))\n",
        "\n",
        "# Select the output tensor of layer conv4_2\n",
        "out = model['conv4_2']\n",
        "\n",
        "# Set a_C to be the hidden layer activation from the layer we have selected\n",
        "a_C = sess.run(out)\n",
        "\n",
        "# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] \n",
        "# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
        "# when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
        "a_G = out\n",
        "\n",
        "# Compute the content cost\n",
        "J_content = compute_content_cost(a_C, a_G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_bSBnkYLzkM"
      },
      "source": [
        "#### Style cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfBjLlTnL2Ev"
      },
      "source": [
        "# Assign the input of the model to be the \"style\" image \n",
        "sess.run(model['input'].assign(style_image))\n",
        "\n",
        "# Compute the style cost\n",
        "J_style = compute_style_cost(model, STYLE_LAYERS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTjo2GWxL2va"
      },
      "source": [
        "### 연습 문제 : total cost\n",
        "\n",
        "- 이제 J_content 및 J_style이 있으므로 `total_cost ()` 를 호출하여 총 비용 J를 계산합니다.\n",
        "- `alpha = 10` 및`beta = 40`을 사용하십시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i0QqgWML2L1"
      },
      "source": [
        "### START CODE HERE ### (1 line)\n",
        "J = None\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOB2SKn5MJUm"
      },
      "source": [
        "### Optimizer\n",
        "\n",
        "* Adam 최적화 프로그램을 사용하여 총 비용 'J'를 최소화하십시오.\n",
        "* 2.0의 학습률을 사용하십시오.\n",
        "* [Adam Optimizer 문서](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td4t9QcMMVfy"
      },
      "source": [
        "# define optimizer (1 line)\n",
        "optimizer = tf.train.AdamOptimizer(2.0)\n",
        "\n",
        "# define train_step (1 line)\n",
        "train_step = optimizer.minimize(J)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp5fz7ybMYM1"
      },
      "source": [
        "### Exercise : implement the model\n",
        "\n",
        "- `model_nn()` 함수를 구현하십시오.\n",
        "- 이 함수는 tensorflow 그래프의 변수를 **초기화**합니다.\n",
        "- 입력 이미지(초기 생성 이미지)를 VGG19 모델의 입력으로 **할당** 합니다\n",
        "- 그리고 `train_step` 텐서(이 함수 위의 코드에서 생성됨)를 많은 단계에 대해서 **실행**합니다.\n",
        "\n",
        "#### Hints\n",
        "* 전역 변수를 초기화하려면 다음을 사용하십시오.\n",
        "```python\n",
        "sess.run(tf.global_variables_initializer())\n",
        "```\n",
        "* 변수를 평가하려면 `sess.run()` 을 실행하십시오.\n",
        "* [assign](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/assign)은 다음과 같이 사용할 수 있습니다.\n",
        "```python\n",
        "model[\"input\"].assign(image)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3Ui0Yh4Mysm"
      },
      "source": [
        "def model_nn(sess, input_image, num_iterations = 200):\n",
        "    \n",
        "    # Initialize global variables (you need to run the session on the initializer)\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    None\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Run the noisy input image (initial generated image) through the model. Use assign().\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    None\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "    \n",
        "        # Run the session on the train_step to minimize the total cost\n",
        "        ### START CODE HERE ### (1 line)\n",
        "        None\n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Compute the generated image by running the session on the current model['input']\n",
        "        ### START CODE HERE ### (1 line)\n",
        "        generated_image = None\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        # Print every 20 iteration.\n",
        "        if i%20 == 0:\n",
        "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
        "            print(\"Iteration \" + str(i) + \" :\")\n",
        "            print(\"total cost = \" + str(Jt))\n",
        "            print(\"content cost = \" + str(Jc))\n",
        "            print(\"style cost = \" + str(Js))\n",
        "            \n",
        "            # save current generated image in the \"/output\" directory\n",
        "            save_image(\"output/\" + str(i) + \".png\", generated_image)\n",
        "    \n",
        "    # save last generated image\n",
        "    save_image('output/generated_image.jpg', generated_image)\n",
        "    \n",
        "    return generated_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJwo9KlRNkZq"
      },
      "source": [
        "다음 셀을 실행하여 예술 작품 이미지를 생성합니다. 20회 반복 할 때마다 CPU에서 약 3분이 소요되고, 약 140 회 반복 후에 매력적인 결과를 출력하기 시작합니다. Neural Style Transfer는 일반적으로 GPU를 사용하여 훈련됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgEW9zBdNuKA"
      },
      "source": [
        "model_nn(sess, generated_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqAFRVsJNw2d"
      },
      "source": [
        "**모범 답안**:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <b>Iteration 0 : </b>\n",
        "        </td>\n",
        "        <td>\n",
        "           total cost = 5.05035e+09 <br>\n",
        "           content cost = 7877.67 <br>\n",
        "           style cost = 1.26257e+08\n",
        "        </td>\n",
        "    </tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhAX9nkbODk_"
      },
      "source": [
        "끝났습니다! 이를 실행 한 후 노트북 상단 표시 줄에서 \"파일\"을 클릭 한 다음 \"열기\"를 클릭합니다. 저장된 모든 이미지를 보려면 \"/output\" 디렉토리로 이동하십시오. 생성 된 이미지를 보려면 \"generated_image\" 를 여십시오! :)\n",
        "\n",
        "오른쪽에 아래에 표시된 이미지가 표시되어야합니다.\n",
        "\n",
        "<img src = \"images / louvre_generated.png\"style = \"width : 800px; height : 300px;\">\n",
        "\n",
        "초기 결과를보기 위해 너무 오래 기다리지 않았으므로 이에 따라 하이퍼 파라미터를 설정했습니다. 최상의 결과를 얻으려면 최적화 알고리즘을 더 오래 (그리고 아마도 더 작은 학습률로) 실행하는 것이 더 효과적 일 수 있습니다. 이 과제를 완료하고 제출 한 후 다시 돌아와서이 노트북을 더 많이 사용하고 더보기 좋은 이미지를 생성 할 수 있는지 확인하시기 바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN-w-UAGOLzF"
      },
      "source": [
        "다음은 몇 가지 다른 예입니다.\n",
        "\n",
        "- 반 고흐 (별이 빛나는 밤) 스타일의 고대 도시 페르 세 폴리스 (이란)의 아름다운 유적\n",
        "\n",
        "<img src=\"arts/perspolis_vangogh.png\" style=\"width:750px;height:300px;\">\n",
        "\n",
        "- 이스파한의 도자기 카시 양식으로 파 사르가 대에있는 고레스 대왕의 무덤.\n",
        "\n",
        "<img src=\"arts/pasargad_kashi.png\" style=\"width:750px;height:300px;\">\n",
        "\n",
        "- 추상적 인 파란색 유체 페인팅 스타일의 난류 유체에 대한 과학적 연구.\n",
        "\n",
        "<img src=\"arts/circle_abstract.png\" style=\"width:750px;height:300px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvGcTQsJOnaF"
      },
      "source": [
        "## 5 - Test with your own Image(Optional/Ungraded)\n",
        "\n",
        "마지막으로 자신의 이미지에서 알고리즘을 다시 실행할 수도 있습니다!\n",
        "\n",
        "파트 4로 돌아가서 자신의 사진으로 콘텐츠 이미지와 스타일 이미지를 변경합니다. 자세한 내용은 다음과 같습니다.\n",
        "\n",
        "1. 노트북 상단 탭에서 \"파일 -> 열기\"를 클릭합니다.\n",
        "2. \"/images\"로 이동하여 이미지를 업로드하고 (규격:(WIDTH=300, HEIGHT=225)), 예를 들어 \"my_content.png\" 및 \"my_style.png\"로 이름을 바꿉니다.\n",
        "3. (3.4) 부분의 코드를 다음에서 변경합니다.\n",
        "```python\n",
        "content_image = scipy.misc.imread (\"images/louvre.jpg\")\n",
        "style_image = scipy.misc.imread (\"images/claude-monet.jpg\")\n",
        "```\n",
        "에:\n",
        "```python\n",
        "content_image = scipy.misc.imread (\"images/my_content.jpg\")\n",
        "style_image = scipy.misc.imread (\"images/my_style.jpg\")\n",
        "```\n",
        "4. 셀을 다시 실행합니다 (노트북의 상단 탭에서 커널을 다시 시작해야 할 수 있음).\n",
        "\n",
        "생성 된 이미지를 해시 태그 #deeplearniNgAI 또는 직접 태그를 통해 소셜 미디어에서 공유 할 수 있습니다!\n",
        "\n",
        "하이퍼 파라미터를 조정할 수도 있습니다.\n",
        "- 스타일을 나타내는 레이어는 무엇입니까? **STYLE_LAYERS**\n",
        "- 알고리즘을 몇 번 반복 하시겠습니까? **num_iterations**\n",
        "- 콘텐츠와 스타일 사이의 상대적 가중치는 무엇입니까? **alpha/beta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUqzYS2yP5fR"
      },
      "source": [
        "## 6 - Conclusion\n",
        "\n",
        "이 과제를 완료했습니다. 이제 Neural Style Transfer를 사용하여 예술 작품 이미지를 생성 할 수 있습니다. 최적화 알고리즘이 신경망의 파라미터가 아닌 픽셀 값을 업데이트하는 모델을 구축하는 것도 이번이 처음입니다. 딥 러닝에는 다양한 유형의 모델이 있으며 이것은 그중 하나 일뿐입니다!\n",
        "\n",
        "## 기억해야 할 사항\n",
        "- Neural Style Transfer는 콘텐츠 이미지 C와 스타일 이미지 S가 주어지면 예술적 이미지를 생성 할 수있는 알고리즘입니다.\n",
        "- 사전 훈련 된 ConvNet을 기반으로 한 representation(은닉층의 활성화)을 사용합니다.\n",
        "- content cost function는 하나의 히든 레이어 활성화를 사용하여 계산됩니다.\n",
        "- 한 레이어의 style cost function은 해당 레이어의 활성화에 대한 Gram matrix을 사용하여 계산됩니다. total cost function은 여러 숨겨진 레이어를 사용하여 얻습니다.\n",
        "- total cost function을 최적화하면 새로운 이미지가 합성됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4GFL853QaU6"
      },
      "source": [
        "### References:\n",
        "\n",
        "The Neural Style Transfer algorithm was due to Gatys et al. (2015). Harish Narayanan and Github user \"log0\" also have highly readable write-ups from which we drew inspiration. The pre-trained network used in this implementation is a VGG network, which is due to Simonyan and Zisserman (2015). Pre-trained weights were from the work of the MathConvNet team. \n",
        "\n",
        "- Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576) \n",
        "- Harish Narayanan, [Convolutional neural networks for artistic style transfer.](https://harishnarayanan.org/writing/artistic-style-transfer/)\n",
        "- Log0, [TensorFlow Implementation of \"A Neural Algorithm of Artistic Style\".](http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style)\n",
        "- Karen Simonyan and Andrew Zisserman (2015). [Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556.pdf)\n",
        "- [MatConvNet.](http://www.vlfeat.org/matconvnet/pretrained/)"
      ]
    }
  ]
}